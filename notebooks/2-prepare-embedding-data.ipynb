{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Embeddings for RAG Systems\n",
    "\n",
    "In the first notebook, we explored how Large Language Models work and the basics of RAG (Retrieval Augmented Generation). We learned that RAG systems enhance LLM responses by retrieving relevant context from our own data before generating answers. \n",
    "Still there is 1 open question: how to decide which data to retrieve to send for the language model in a Rag Application?\n",
    "Now, we'll go into the core component that makes RAG possible: embeddings. We'll learn how to convert text into numerical vectors that computers can compare for deciding which to send to the language model.\n",
    "\n",
    "\n",
    "Open [this image](rag_architecture_workshop.png) for an overview of rag concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting language to numbers\n",
    "\n",
    "\n",
    "Embeddings are numerical representations of text that capture semantic meaning. They convert words or sentences into vectors (lists of numbers) that can be compared mathematically.\n",
    "\n",
    "- Similar texts should have similar vector representations\n",
    "- The dimensionality and quality of embeddings affects performance\n",
    "- Different embedding models are trained on different data\n",
    "\n",
    "\n",
    "Embeddings transform text into numbers through several steps:\n",
    "\n",
    "1. **Tokenization**: Breaking text into smaller pieces\n",
    "   - Words: \"hello world\" → [\"hello\", \"world\"]\n",
    "   - Subwords: \"playing\" → [\"play\", \"##ing\"]\n",
    "   - Characters: For languages like Chinese\n",
    "\n",
    "2. **Token IDs**: Each token gets mapped to a number\n",
    "   - Example: \"hello\" → 15234\n",
    "   - These mappings are stored in the model's vocabulary\n",
    "\n",
    "3. **Neural Network Processing**:\n",
    "   - Tokens pass through multiple transformer layers\n",
    "   - Each layer learns different aspects (syntax, semantics, context)\n",
    "   - Final layer outputs the embedding vector\n",
    "\n",
    "4. **Vector Space**: The final embedding places similar meanings close together\n",
    "   - Each dimension captures different semantic features\n",
    "   - Typical sizes: 384, 768, or 1024 dimensions\n",
    "\n",
    "\n",
    "For this workshop we will be using sentences-tranformers, a popular open-soruce library for working with text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean.machado@getyourguide.com/prj/rag-workshop/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I love machine learning\n",
      "Tokens: ['i', 'love', 'machine', 'learning']\n",
      "Token IDs: [101, 1045, 2293, 3698, 4083, 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding shape: (384,)\n",
      "First 5 dimensions: [-0.04363637 -0.05905439  0.08201234 -0.01076717  0.06119593]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "text = \"I love machine learning\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.encode(text)\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token IDs:\", token_ids)\n",
    "\n",
    "# 2. Getting Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(\"\\nEmbedding shape:\", embedding.shape)\n",
    "print(\"First 5 dimensions:\", embedding[:5])\n",
    "# the output can take some seconds to appear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Embedding Dimensions\n",
    "\n",
    "Each dimension in an embedding vector captures different semantic features:\n",
    "- Word types (noun, verb, etc.)\n",
    "- Topics (technology, nature, etc.)\n",
    "- Sentiment (positive, negative)\n",
    "- And many other abstract features\n",
    "\n",
    "The more dimensions, the more nuanced the representation, but also:\n",
    "- More computational cost\n",
    "- More storage needed\n",
    "- Risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small model dimensions: (384,)\n",
      "Large model dimensions: (768,)\n",
      "Small model speed: 7.45ms\n",
      "Large model speed: 11.57ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def time_it(func, runs=3):\n",
    "    \"\"\"Time a function over multiple runs\"\"\"\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        func()\n",
    "        times.append(time.time() - start)\n",
    "    return f\"{(sum(times) / runs) * 1000:.2f}ms\"\n",
    "\n",
    "small_model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dims\n",
    "large_model = SentenceTransformer('all-mpnet-base-v2')  # 768 dims\n",
    "\n",
    "text = \"This is a test sentence\"\n",
    "small_emb = small_model.encode(text)\n",
    "large_emb = large_model.encode(text)\n",
    "\n",
    "print(f\"Small model dimensions: {small_emb.shape}\")\n",
    "print(f\"Large model dimensions: {large_emb.shape}\")\n",
    "print(f\"Small model speed: {time_it(lambda: small_model.encode(text))}\")\n",
    "print(f\"Large model speed: {time_it(lambda: large_model.encode(text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how embeddings group similar concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores (closer to 1 = more similar):\n",
      "pizza-burger: 0.460\n",
      "coffee-tea: 0.616\n",
      "pizza-coffee: 0.458\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create word groups with clear relationships\n",
    "words = {\n",
    "    'food': ['pizza', 'burger', 'pasta', 'sushi'],\n",
    "    'drinks': ['coffee', 'tea', 'juice', 'water'],\n",
    "    'colors': ['red', 'blue', 'green', 'yellow']\n",
    "}\n",
    "\n",
    "# Get embeddings for all words\n",
    "all_words = [word for group in words.values() for word in group]\n",
    "embeddings = model.encode(all_words)\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot with different colors for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#FF9999', '#66B2FF', '#99FF99']\n",
    "for (group_name, group_words), color in zip(words.items(), colors):\n",
    "    start_idx = all_words.index(group_words[0])\n",
    "    x = embeddings_2d[start_idx:start_idx+4, 0]\n",
    "    y = embeddings_2d[start_idx:start_idx+4, 1]\n",
    "    plt.scatter(x, y, c=color, label=group_name)\n",
    "    \n",
    "    # Add word labels\n",
    "    for i, word in enumerate(group_words):\n",
    "        plt.annotate(word, (x[i], y[i]))\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\" cosine similarity is a measure of similarity between two vectors the higher the value the more similar the vectors are \"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "# Show some similarity scores\n",
    "print(\"\\nSimilarity Scores (closer to 1 = more similar):\")\n",
    "print(f\"pizza-burger: {cosine_similarity(model.encode('pizza'), model.encode('burger')):.3f}\")\n",
    "print(f\"coffee-tea: {cosine_similarity(model.encode('coffee'), model.encode('tea')):.3f}\")\n",
    "print(f\"pizza-coffee: {cosine_similarity(model.encode('pizza'), model.encode('coffee')):.3f}\")\n",
    "\n",
    "plt.title(\"Word Embeddings Visualized in 2D\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-language models\n",
    "\n",
    "You can find different models in english, and all major languages; sometimes they also support more than 1 language.\n",
    "If you are building an application in a language other than english, consider using a language specific model as they usually perform better for the following reasons:\n",
    "\n",
    "1. **Vocabulary Coverage**: \n",
    "   - Better handling of language-specific words\n",
    "   - Proper subword tokenization for morphologically rich languages\n",
    "\n",
    "2. **Cultural Context**:\n",
    "   - Understanding idioms and expressions\n",
    "   - Proper handling of formal/informal speech\n",
    "\n",
    "3. **Syntactic Structure**:\n",
    "   - Word order differences\n",
    "   - Grammar patterns\n",
    "\n",
    "This is why we use different models in our code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other practical advice for using embeddings\n",
    "\n",
    "1. **Choosing Model Size**:\n",
    "   - Smaller models (384 dims): Faster, good for simple tasks\n",
    "   - Larger models (768+ dims): Better quality, slower\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - Clean text (remove noise)\n",
    "   - Consistent casing\n",
    "   - Handle special characters\n",
    "\n",
    "3. **Storage Considerations**:\n",
    "   - 384 dimensions × 4 bytes = ~1.5KB per embedding\n",
    "   - Plan database capacity accordingly\n",
    "\n",
    "Lets now compare an english and a german model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-embeddings-v3:\n",
      "- custom_st.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- mha.py\n",
      "- stochastic_depth.py\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- embedding.py\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- rotary.py\n",
      "- block.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load different embedding models\n",
    "english_model = SentenceTransformer('all-MiniLM-L6-v2')  # English-focused\n",
    "german_model = SentenceTransformer(\"jinaai/jina-embeddings-v3\", trust_remote_code=True) # Multi-Lingual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Comparing Similar Sentences\n",
    "\n",
    "Let's see how embeddings capture similarity between sentences in different languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English Model Results:\n",
      "I love Berlin <-> Berlin is my favorite city: 0.904\n",
      "I love Berlin <-> I hate vegetables: 0.076\n",
      "\n",
      "German-English Model Results:\n",
      "Ich liebe Berlin <-> Berlin ist meine Lieblingsstadt: 0.946\n",
      "Ich liebe Berlin <-> Ich hasse Gemüse: 0.404\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "def compare_sentences(model, sent1, sent2):\n",
    "    emb1 = model.encode(sent1)\n",
    "    emb2 = model.encode(sent2)\n",
    "    return cosine_similarity(emb1, emb2)\n",
    "\n",
    "# Test pairs in different languages\n",
    "english_pairs = [\n",
    "    (\"I love Berlin\", \"Berlin is my favorite city\"),\n",
    "    (\"I love Berlin\", \"I hate vegetables\")\n",
    "]\n",
    "\n",
    "german_pairs = [\n",
    "    (\"Ich liebe Berlin\", \"Berlin ist meine Lieblingsstadt\"),\n",
    "    (\"Ich liebe Berlin\", \"Ich hasse Gemüse\")\n",
    "]\n",
    "\n",
    "print(\"\\nEnglish Model Results:\")\n",
    "for sent1, sent2 in english_pairs:\n",
    "    sim = compare_sentences(english_model, sent1, sent2)\n",
    "    print(f\"{sent1} <-> {sent2}: {sim:.3f}\")\n",
    "\n",
    "print(\"\\nGerman-English Model Results:\")\n",
    "for sent1, sent2 in german_pairs:\n",
    "    sim = compare_sentences(german_model, sent1, sent2)\n",
    "    print(f\"{sent1} <-> {sent2}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Cross-lingual Capabilities\n",
    "\n",
    "Let's compare how different models handle cross-lingual similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-lingual similarity:\n",
      "\n",
      "English-only model:\n",
      "The weather is nice today <-> Das Wetter ist heute schön: 0.084\n",
      "I need a coffee <-> Ich brauche einen Kaffee: 0.299\n",
      "Berlin is the capital of Germany <-> Berlin ist die Hauptstadt von Deutschland: 0.680\n",
      "\n",
      "German-English model:\n",
      "The weather is nice today <-> Das Wetter ist heute schön: 0.869\n",
      "I need a coffee <-> Ich brauche einen Kaffee: 0.944\n",
      "Berlin is the capital of Germany <-> Berlin ist die Hauptstadt von Deutschland: 0.867\n"
     ]
    }
   ],
   "source": [
    "cross_lingual_pairs = [\n",
    "    (\"The weather is nice today\", \"Das Wetter ist heute schön\"),\n",
    "    (\"I need a coffee\", \"Ich brauche einen Kaffee\"),\n",
    "    (\"Berlin is the capital of Germany\", \"Berlin ist die Hauptstadt von Deutschland\")\n",
    "]\n",
    "\n",
    "print(\"Cross-lingual similarity:\")\n",
    "print(\"\\nEnglish-only model:\")\n",
    "for en, de in cross_lingual_pairs:\n",
    "    sim = compare_sentences(english_model, en, de)\n",
    "    print(f\"{en} <-> {de}: {sim:.3f}\")\n",
    "\n",
    "print(\"\\nGerman-English model:\")\n",
    "for en, de in cross_lingual_pairs:\n",
    "    sim = compare_sentences(german_model, en, de)\n",
    "    print(f\"{en} <-> {de}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Domain-Specific Comparisons\n",
    "\n",
    "Let's see how models handle domain-specific terminology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tourism domain comparisons:\n",
      "\n",
      "Pair: Guided tour of the Brandenburg Gate <-> Führung durch das Brandenburger Tor\n",
      "English model similarity: 0.470\n",
      "German-English model similarity: 0.824\n",
      "\n",
      "Pair: Skip the line tickets for museums <-> Eintrittskarten ohne Anstehen für Museen\n",
      "English model similarity: 0.196\n",
      "German-English model similarity: 0.818\n",
      "\n",
      "Pair: Best restaurants in Berlin <-> Beste Restaurants in Berlin\n",
      "English model similarity: 0.941\n",
      "German-English model similarity: 0.938\n"
     ]
    }
   ],
   "source": [
    "tourism_pairs = [\n",
    "    (\"Guided tour of the Brandenburg Gate\", \"Führung durch das Brandenburger Tor\"),\n",
    "    (\"Skip the line tickets for museums\", \"Eintrittskarten ohne Anstehen für Museen\"),\n",
    "    (\"Best restaurants in Berlin\", \"Beste Restaurants in Berlin\")\n",
    "]\n",
    "\n",
    "print(\"Tourism domain comparisons:\")\n",
    "for en, de in tourism_pairs:\n",
    "    en_sim = compare_sentences(english_model, en, de)\n",
    "    de_sim = compare_sentences(german_model, en, de)\n",
    "    print(f\"\\nPair: {en} <-> {de}\")\n",
    "    print(f\"English model similarity: {en_sim:.3f}\")\n",
    "    print(f\"German-English model similarity: {de_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Language Support**: Models trained on specific languages perform better for those languages\n",
    "2. **Cross-lingual Capabilities**: Specialized multilingual models handle cross-language comparisons better\n",
    "3. **Domain Relevance**: Consider your use case when choosing an embedding model\n",
    "\n",
    "When building a RAG system:\n",
    "- Choose embedding models that match your content languages\n",
    "- Consider using specialized models for specific domains\n",
    "- Test different models with your actual use cases (And evaluate those)\n",
    "- Balance performance vs computational cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn to play with Embedding Models!\n",
    "\n",
    "## Concrete Example: Building a Smart Support System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic similarity search:\n",
      "\n",
      "Query: 'forgot password'\n",
      "Match: 'How do I reset my password?' (Score: 0.779)\n",
      "Match: 'My account is locked' (Score: 0.609)\n",
      "\n",
      "Query: 'package not here yet'\n",
      "Match: 'How do I track my package?' (Score: 0.417)\n",
      "Match: 'Where's my order?' (Score: 0.414)\n",
      "\n",
      "Query: 'want my money back'\n",
      "Match: 'Can I get a refund?' (Score: 0.610)\n",
      "Match: 'How do I cancel my subscription?' (Score: 0.334)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def find_most_similar(query, message_list, model, top_k=1):\n",
    "    \"\"\"\n",
    "    Find the most similar customer messages\n",
    "    Returns: List of (message, score) tuples\n",
    "    \"\"\"\n",
    "    query_embedding = model.encode(query)\n",
    "    message_embeddings = model.encode(message_list)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = [\n",
    "        cosine_similarity(query_embedding, msg_emb) \n",
    "        for msg_emb in message_embeddings\n",
    "    ]\n",
    "    \n",
    "    # Get top-k matches\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return [(message_list[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "support_messages = {\n",
    "    'account': [\n",
    "        \"How do I reset my password?\",\n",
    "        \"I can't log into my account\",\n",
    "        \"How do I change my email?\",\n",
    "        \"My account is locked\"\n",
    "    ],\n",
    "    'shipping': [\n",
    "        \"Where's my order?\",\n",
    "        \"Do you ship internationally?\",\n",
    "        \"How do I track my package?\",\n",
    "        \"Can I change my shipping address?\"\n",
    "    ],\n",
    "    'billing': [\n",
    "        \"How do I update my payment method?\",\n",
    "        \"Can I get a refund?\",\n",
    "        \"When will I be charged?\",\n",
    "        \"How do I cancel my subscription?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_queries = [\n",
    "    \"forgot password\",\n",
    "    \"package not here yet\",\n",
    "    \"want my money back\"\n",
    "]\n",
    "\n",
    "print(\"Basic similarity search:\")\n",
    "for query in test_queries:\n",
    "    matches = find_most_similar(query, [msg for msgs in support_messages.values() for msg in msgs], model, top_k=2)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    for match, score in matches:\n",
    "        print(f\"Match: '{match}' (Score: {score:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Try these experiments like the example above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Category Classification\n",
    "def classify_message(query, categories=support_messages):\n",
    "    \"\"\"\n",
    "    Your turn! Implement a function that:\n",
    "    1. Takes a customer query\n",
    "    2. Returns the most likely category (account/shipping/billing)\n",
    "    Hint: Compare query with all messages in each category\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# 2. Threshold Testing\n",
    "def is_relevant_query(query, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Your turn! Implement a function that:\n",
    "    1. Checks if a query is relevant to our support topics\n",
    "    2. Returns True if similarity is above threshold\n",
    "    Try with queries like \"What's the weather?\" vs \"Reset password\"\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# 4. Bonus: Multi-Language Support\n",
    "# Try adding some non-English support messages and queries!\n",
    "# Does the model handle them well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chunking\n",
    "\n",
    "## Why Do We Need Chunking?\n",
    "\n",
    "In the previous notebook, we saw how RAG systems use external information to make LLMs smarter. But there's a catch - we might not want to just feed entire documents into our system. We may want to break them into smaller, manageable pieces (chunks) because:\n",
    "\n",
    "1. **Context Window Limits**: LLMs have a maximum amount of text they can process at once\n",
    "2. **Relevant Information**: Smaller chunks help us find and retrieve only the most relevant parts of a document\n",
    "3. **Better Matching**: It's easier to match a question with a small, focused chunk than an entire document\n",
    "\n",
    "For example, if someone asks \"What is RAG?\" we want to find and use just the RAG-related chunk, not the entire document about AI concepts.\n",
    "\n",
    "## Chunking Strategies\n",
    "\n",
    "We'll explore two main ways to break up text:\n",
    "1. Simple character-based chunking (split every X characters)\n",
    "2. Smarter paragraph-based chunking (respect natural text boundaries)\n",
    "\n",
    "Let's see how these work in practice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topics\\nWhat Are Large Language Models (LLMs)?\\nLarge Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. These deep learning algorithms are trained on massive datasets of text, enabling them to predict and generate language based on given prompts. By learning patterns, structures, and relationships in text, LLMs can produce human-like responses.\\nLLMs are a subset of a broader technology known as language models, which all share the abil'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's load our data\n",
    "with open('../data/data_example.md', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Character-based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of character-based chunks: 98\n",
      "\n",
      "First two chunks:\n",
      "Chunk 1: Topics\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. These deep learning algorithms are trained on massive datasets of text, enabling them to predict and generate language based on given prompts. By learning patterns, structures, and relationships in text, LLMs can produce human-like responses.\n",
      " \n",
      "\n",
      "Chunk 2: s in text, LLMs can produce human-like responses.\n",
      "LLMs are a subset of a broader technology known as language models, which all share the ability to process and generate text that resembles natural language, performing tasks related to natural language processing (NLP). However, LLMs stand out due to their significant size, characterized by two main factors:\n",
      "Large Training Datasets: LLMs are trained using vast amounts of data, allowing them to learn a wide range of language patterns and nuances. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_characters(text, chunk_size=500, overlap=50):\n",
    "    \"\"\"\n",
    "    Split text into chunks of roughly equal size\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        # Get chunk with specified size\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        \n",
    "        # If we're not at the end, try to break at a period or newline\n",
    "        if end < len(text):\n",
    "            last_period = chunk.rfind('.')\n",
    "            last_newline = chunk.rfind('\\n')\n",
    "            break_point = max(last_period, last_newline)\n",
    "            \n",
    "            if break_point != -1:\n",
    "                chunk = chunk[:break_point + 1]\n",
    "                end = start + break_point + 1\n",
    "        \n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Let's try it out\n",
    "char_chunks = chunk_by_characters(text, chunk_size=500)\n",
    "print(f\"Number of character-based chunks: {len(char_chunks)}\")\n",
    "print(\"\\nFirst two chunks:\")\n",
    "print(\"Chunk 1:\", char_chunks[0], \"\\n\")\n",
    "print(\"Chunk 2:\", char_chunks[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Smarter Paragraph-based Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraph-based chunks: 3\n",
      "\n",
      "First two chunks:\n",
      "Chunk 1: Topics\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. These deep learning algorithms are trained on massive datasets of text, enabling them to predict and generate language based on given prompts. By learning patterns, structures, and relationships in text, LLMs can produce human-like responses.\n",
      "LLMs are a subset of a broader technology known as language models, which all share the ability to process and generate text that resembles natural language, performing tasks related to natural language processing (NLP). However, LLMs stand out due to their significant size, characterized by two main factors:\n",
      "Large Training Datasets: LLMs are trained using vast amounts of data, allowing them to learn a wide range of language patterns and nuances.\n",
      "Huge Number of Learnable Parameters: LLMs have a massive number of learnable parameters. These parameters represent the underlying structure of the training data and enable the models to perform tasks on new or never-before-seen data effectively.\n",
      "These characteristics make LLMs particularly powerful and versatile in handling complex language-related tasks.\n",
      "How do Large Language Models (LLMs) work?\n",
      "Architecture\n",
      "LLMs are based on the transformer architecture, which consists of an encoder and a decoder. An encoder processes and encodes the input data into a set of embeddings, and a decoder generates the output by interpreting these embeddings.\n",
      "Transformer components:\n",
      "Attention mechanism: This mechanism allows the model to weigh the importance of different words in a sentence when making predictions. Self-attention helps the model focus on relevant parts of the input text.\n",
      "Layers: Multiple layers of attention and feed-forward neural networks are stacked to build deep models. Each layer helps the model learn more complex representations of the input data.\n",
      "Training process\n",
      "Training an LLM involves several steps:\n",
      "Data collection\n",
      "Corpus: The model is trained on a massive corpus of text data, which can include books, articles, websites, and other text sources. The goal is to expose the model to diverse language patterns and knowledge.\n",
      "Preprocessing\n",
      "Tokenization: Text is broken down into smaller units called tokens (words, subwords, or characters). These tokens are then converted into numerical representations (embeddings).\n",
      "Training\n",
      "Objective: The primary training objective for LLMs is to predict the next word in a sentence. This is known as language modeling.\n",
      "Optimization: The model’s parameters are adjusted using optimization algorithms like stochastic gradient descent (SGD) to minimize the prediction error. The loss function measures the difference between the model’s predictions and the actual next words in the training data.\n",
      "Inference\n",
      "Once trained, the model can be used for various language tasks:\n",
      "Text generation\n",
      "Text completion\n",
      "Question answering\n",
      "Translation\n",
      "Challenges of Large Language Models\n",
      "Implementing large language models (LLMs) comes with several common pitfalls that are applicable regardless of whether a model is being customized, fine-tuned, or built from scratch:\n",
      "Vulnerability to Adversarial Examples: LLMs can be susceptible to adversarial examples—inputs specifically crafted to deceive the models into making errors. This poses significant security concerns, particularly in sensitive applications like healthcare or finance.\n",
      "Lack of Interpretability: Interpretability refers to the ability to understand and predict the decisions made by models. LLMs with low interpretability can be challenging to troubleshoot and evaluate, as it may not be clear how they are making their decisions or how accurate or unbiased those decisions are. This issue is especially problematic in high-stakes use cases, such as fraud detection, and in industries requiring high transparency, such as healthcare and finance.\n",
      "Generic Responses: LLMs may sometimes provide un-customized, generic answers and may not always effectively respond to human input or understand the intent behind it. Techniques like Reinforcement Learning from Human Feedback (RLHF) can help improve model performance over time based on positive or negative human feedback. However, LLMs can sometimes reproduce text data they’ve encountered during training, which raises ethical concerns and may expose users to copyright and legal issues.\n",
      "Ethical Concerns: There are ethical questions regarding the use of LLMs for important decision-making tasks, such as selecting the most qualified job candidates based on resumes, especially without human oversight. Additionally, it’s important to consider whether it is ethical to use LLMs for tasks traditionally performed by humans, particularly white-collar workers.\n",
      "Generation of Inappropriate Content: LLMs, often trained on extensive corpora of internet texts, can generate toxic, biased, and otherwise inappropriate or harmful content. Users must be mindful of this risk when deploying LLMs.\n",
      "Resource Intensity: Developing, implementing, and maintaining LLMs requires substantial computing power, storage, datasets, expertise, and financial resources. This can be a significant barrier for those looking to build proprietary LLMs from scratch.\n",
      "Data Privacy and Security: LLMs often require large amounts of data, which can raise privacy and security concerns. Ensuring that data used for training and operation is secure and compliant with privacy regulations is crucial.\n",
      "Bias and Fairness: LLMs can inadvertently perpetuate or amplify biases present in their training data. Ensuring fairness and mitigating bias in LLM outputs is a significant challenge, particularly in applications affecting people's lives and well-being.\n",
      "Scalability: As LLMs grow in size and complexity, scaling them efficiently becomes a challenge. This includes not only the computational resources required but also the ability to deploy and maintain them in production environments.\n",
      "Ways to Build LLMs\n",
      "Building large language models from scratch is often impractical, especially for those whose core focus is not related to AI or NLP technologies. The process is extremely time-consuming and resource-intensive. Therefore, most users are more likely to opt for customizing existing models to suit their specific needs.\n",
      "Customizing existing base models—also known as pre-trained models (PLMs)—typically involves three essential steps:\n",
      "Finding a Well-Suited Foundation Model (PLM): This step involves selecting an appropriate base model by considering factors such as the ideal model size, training tasks and datasets, and LLM providers.\n",
      "Fine-Tuning the Model: Base models can be fine-tuned on a specific corpus and for a specific use case. For example, a text classification base model may be fine-tuned for sentiment analysis or trained using legal records to become proficient in legal terminology.\n",
      "Optimizing the Model: Models can be further optimized using techniques such as Reinforcement Learning from Human Feedback (RLHF), where the model is updated based on positive or negative human feedback on its predictions or classifications. RLHF is particularly promising and has been used successfully in models like ChatGPT.\n",
      "Alternatively, users may choose to customize base models using parameter-efficient techniques like adapters and p-tuning. Customization can yield especially accurate models when the base model is trained on tasks similar to the selected downstream tasks. For example, a base text classification model may be a good candidate for customization for sentiment analysis, as the two tasks are very similar. The model can leverage the knowledge gained during training to perform sentiment analysis tasks more effectively.\n",
      "Examples of Well-Known LLMs\n",
      "GPT series: Developed by OpenAI, they are proprietary and very powerful.\n",
      "Mistral Series: Developed by Mistral AI, built by an EU company.\n",
      "LLaMa series: Developed by Meta.\n",
      "Claude: Developed by Anthropic.\n",
      "Closed Source vs. Open Source LLMs\n",
      "Open-Source LLMs\n",
      "Open-source large language models (LLMs) are characterized by their public availability, meaning that the source code, model architecture, and sometimes the training data are accessible to everyone. These models are free to use, modify, and distribute, making them highly cost-effective. Development is often driven by community contributions and collaboration, allowing for continuous improvements and innovations. Examples of open-source LLMs include BERT, RoBERTa, BLOOM, and LLaMA.\n",
      "Advantages:\n",
      "Open-source models do not have licensing fees, making them free to use.\n",
      "They offer full transparency, providing complete access to the model’s workings, which helps in understanding and auditing the model.\n",
      "Users have high flexibility to modify and adapt the model to suit specific needs and requirements.\n",
      "Disadvantages:\n",
      "Professional support is limited, often relying on community help and documentation.\n",
      "Users are responsible for maintaining and updating their implementations, which can be resource-intensive.\n",
      "Closed-Source LLMs\n",
      "Closed-source LLMs are developed and maintained by private companies or organizations, with the source code, training data, and model architecture kept proprietary. Access to these models is typically provided through APIs or licensed software, often involving subscription fees or pay-per-use pricing models. These models come with professional support, regular updates, and maintenance provided by the developers. Examples of closed-source LLMs include GPT-4, Claude, and Megatron-Turing NLG.\n",
      "Advantages:\n",
      "Closed-source models are often highly optimized for performance and accuracy, providing superior results.\n",
      "They come with access to professional support and troubleshooting, ensuring reliability.\n",
      "Managed environments offer better security and compliance with regulations, which is crucial for many businesses.\n",
      "Disadvantages:\n",
      "These models can be expensive due to subscription fees or usage costs.\n",
      "Users have limited insight into the model’s internal workings, which can be a drawback for transparency and trust.\n",
      "There is limited ability to modify or adapt the model for specific needs, reducing flexibility.\n",
      "Closed-source LLMs are proprietary, with code and models kept private, while open-source LLMs allow public access to the model architecture and often the training data, enabling more transparency and community-driven improvements.\n",
      "Foundation Language Models vs. Fine-Tuned Language Models\n",
      "Foundation language models, such as MT-NLG and GPT-3, are typically what is referred to when discussing large language models (LLMs). These models are trained on vast amounts of data and can perform a wide variety of natural language processing (NLP) tasks, including answering questions, generating book summaries, and translating sentences.\n",
      "Due to their size, foundation models can perform well even with limited domain-specific data. They exhibit good general performance across tasks but may not excel at any one specific task.\n",
      "Fine-tuned language models, on the other hand, are derived from foundation LLMs and customized for specific use cases or domains. This specialization allows them to perform particular tasks more effectively than foundation models.\n",
      "Fine-tuned models are not only better at specific tasks but are also lighter and generally easier to train. The process of fine-tuning a foundation model for specific objectives typically involves parameter-efficient customization techniques such as p-tuning, prompt tuning, and adapters. These methods are less time-consuming and expensive than fine-tuning the entire model, although they may result in somewhat poorer performance.\n",
      "Evolution of Large Language Models\n",
      "Historically, AI systems focused on processing and analyzing data rather than generating it. This distinction highlights the difference between Perceptive AI and Generative AI. Generative AI has become increasingly prevalent since around 2020, following the adoption of transformer models and the development of more robust LLMs on a large scale.\n",
      "The advent of LLMs has revolutionized the paradigm of NLP models' design, training, and usage. To understand this shift, it is helpful to compare LLMs to previous NLP models across three historical regimes: pre-transformers NLP, transformers NLP, and LLM NLP.\n",
      "Pre-transformers NLP: This period was marked by models that relied on human-crafted rules rather than machine learning algorithms. These models were suitable for simpler tasks like text classification but struggled with more complex tasks such as machine translation. Rule-based models also performed poorly in edge-case scenarios due to their inability to make accurate predictions for unseen data. Later, simple neural networks like RNNs and LSTMs improved context-dependent predictions but were limited in processing long text spans.\n",
      "Transformers NLP: Initiated by the rise of the transformer architecture in 2017, transformers could generalize better than RNNs and LSTMs, capture more context, and process larger amounts of data simultaneously. These improvements enabled models to understand longer sequences and perform a wider range of tasks. However, models from this period had limited capabilities due to the lack of large-scale datasets and computational resources. They mainly garnered attention from researchers rather than the general public.\n",
      "LLM NLP: This era began with the launch of OpenAI's GPT-3 in 2020. LLMs like GPT-3 were trained on massive datasets, allowing them to produce more accurate and comprehensive NLP responses. This advancement unlocked new possibilities and brought us closer to achieving \"true\" AI. Additionally, LLMs democratized NLP technology, making it accessible to non-technical users who could now solve various NLP tasks using natural-language prompts.\n",
      "The transition between these methodologies was driven by technological and methodological advancements, including the advent of neural networks, attention mechanisms, transformers, and developments in unsupervised and self-supervised learning. Understanding these concepts is crucial for comprehending how LLMs work and how to build new LLMs from scratch.\n",
      "Fine-Tuning\n",
      "Fine-tuning is a process used to adapt a pre-trained LLM to a specific task or domain by further training it on a smaller, task-specific dataset. This process adjusts the model's parameters to better fit the new data while leveraging the general knowledge it acquired during the initial pre-training phase.\n",
      "Key concepts of fine-tuning:\n",
      "Pre-training: Initially, the LLM is trained on a large and diverse dataset to learn general language patterns, structures, and representations. This phase equips the model with a broad understanding of language.\n",
      "Task-specific adaptation: Fine-tuning involves taking the pre-trained model and training it further on a smaller, task-specific dataset. This dataset is typically much smaller than the one used for pre-training and is focused on the particular task or domain of interest.\n",
      "Parameter adjustment: During fine-tuning, the model's parameters are adjusted to improve performance on the specific task. This helps the model to specialize and perform better on the new data while retaining its general language understanding.\n",
      "Efficiency: Fine-tuning is more efficient than training a model from scratch because it builds on the existing knowledge of the pre-trained model. This reduces the amount of data and computational resources required to achieve good performance on the new task.\n",
      "Examples of fine-tuning:\n",
      "Sentiment analysis:\n",
      "Pre-trained model: A general-purpose LLM (such as Mistral or GPT-4)\n",
      "Fine-tuning dataset: A labeled dataset of movie reviews with sentiment labels (positive or negative).\n",
      "Outcome: The fine-tuned model can accurately classify the sentiment of new movie reviews.\n",
      "Medical Text Analysis:\n",
      "Pre-trained model: A general-purpose LLM (such as Mistral or GPT-4)\n",
      "Fine-tuning dataset: A corpus of medical documents and patient records.\n",
      "Outcome: The fine-tuned model can extract relevant medical information and assist in clinical decision-making.\n",
      "Customer Support:\n",
      "Pre-trained model: A general-purpose LLM.\n",
      "Fine-tuning dataset: A dataset of customer support interactions and resolutions.\n",
      "Outcome: The fine-tuned model can provide accurate and helpful responses to customer inquiries.\n",
      "Retrieval-Augmented Generation (RAG)\n",
      "Retrieval-Augmented Generation (RAG) is a hybrid natural language processing (NLP) approach that combines the strengths of retrieval-based methods and generation-based methods. Traditional language models generate responses based solely on pre-learned patterns and information from their training phase, which can limit the depth or specificity of their responses. RAG addresses this limitation by incorporating external data retrieval into the generation process, allowing the model to produce responses that are not only accurate but also deeply informed by relevant, real-world information.\n",
      "The Architecture of RAG\n",
      "The RAG framework consists of two main components:\n",
      "Retriever Component: The retriever searches a large corpus of documents to find relevant pieces of information based on the input query. It uses techniques like dense passage retrieval (DPR) or term-matching methods like TF-IDF (Term Frequency-Inverse Document Frequency) or BM25 to identify the most relevant documents. Dense retrievers create neural network-based vector embeddings that capture semantic similarities, while sparse retrievers rely on exact term matches.\n",
      "Generator Component: The generator takes the retrieved documents and the original query to produce a final, coherent response. It uses a sequence-to-sequence (seq2seq) model, such as a transformer-based architecture, to generate text that is both contextually relevant and factually accurate. The generator leverages the context provided by the retriever to ensure the output is not just plausible but also rich in detail and accuracy.\n",
      "Workflow of a RAG System\n",
      "The workflow of a RAG system involves several steps to ensure that the final response is both accurate and contextually relevant:\n",
      "Query Processing: The process begins with an input query, which could be a question, prompt, or any input requiring a response.\n",
      "Embedding Model: The query is converted into a vector representation by an embedding model. This vector representation captures the semantic meaning of the query.\n",
      "Vector Database Retrieval: The query vector is used to search through a vector database containing precomputed vectors of potential contexts. The system retrieves the most relevant contexts based on vector similarity.\n",
      "Retrieved Contexts: These contexts are passed to the Large Language Model (LLM). The retrieved documents provide the necessary information to generate a knowledgeable response.\n",
      "LLM Response Generation: The LLM generates a response by synthesizing the retrieved contexts with its pre-existing knowledge. This ensures that the response is not only based on its training data but is also augmented with specific details from the retrieved data.\n",
      "Final Response: The LLM outputs a response that is informed by the external data retrieved during the process, making it more accurate and detailed.\n",
      "Advantages of RAG\n",
      "RAG offers several advantages over traditional language models:\n",
      "Improved Accuracy: By incorporating external information, RAG can provide more accurate and factually correct responses.\n",
      "Contextual Relevance: The hybrid approach ensures that the generated text is contextually relevant, leveraging the strengths of both retrieval and generation methods.\n",
      "Scalability: RAG can handle large datasets and knowledge bases, making it suitable for a wide range of applications.\n",
      "Flexibility: The retrieval component can be updated with new information, ensuring the model remains current and accurate over time. \n",
      "\n",
      "Chunk 2: Applications of RAG\n",
      "RAG has numerous applications across various domains, significantly enhancing the quality and relevance of the outputs generated by language models:\n",
      "Enhancing Chatbots and Conversational Agents:\n",
      "Customer Support: Chatbots equipped with RAG can retrieve product information, FAQs, and support documents to provide detailed and accurate responses to customer inquiries.\n",
      "Personal Assistants: Virtual personal assistants use RAG to pull in real-time data, such as weather information or news, making their interactions more contextually relevant and helpful.\n",
      "Improving Accuracy and Depth in Automated Content Generation:\n",
      "Content Creation: Journalistic AI tools use RAG to fetch relevant facts and figures, leading to articles that are rich with up-to-date information and require less human editing.\n",
      "Copywriting: Marketing bots utilize RAG to generate product descriptions and advertising copy that are not only creative but also factually correct, by referencing a database of product specs and reviews.\n",
      "Application in Question-Answering Systems:\n",
      "Educational Platforms: RAG is used in educational technology to provide students with detailed explanations and additional context for complex subjects by retrieving information from educational databases.\n",
      "Research: AI systems help researchers find answers to scientific questions by referencing a vast corpus of academic papers and generating summaries of relevant studies.\n",
      "Benefits in Various Fields:\n",
      "Healthcare: RAG-powered systems can assist medical professionals by pulling in information from medical journals and patient records to suggest diagnoses or treatments that are informed by the latest research.\n",
      "Customer Service: By retrieving company policies and customer histories, RAG allows service agents to offer personalized and accurate advice, improving customer satisfaction.\n",
      "Education: Teachers can leverage RAG-based tools to create custom lesson plans and learning materials that draw from a broad range of educational content, providing students with diverse perspectives.\n",
      "Additional Applications:\n",
      "Legal Aid: RAG systems can aid in legal research by fetching relevant case law and statutes to assist in drafting legal documents or preparing for cases.\n",
      "Translation Services: Combining RAG with translation models to provide context-aware translations that consider cultural nuances and idiomatic expressions by referencing bilingual text corpora.\n",
      "Challenges in Implementing RAG\n",
      "Despite its advantages, implementing RAG comes with several challenges:\n",
      "Complexity: Combining retrieval and generation processes adds complexity to the model architecture, making it more challenging to develop and maintain.\n",
      "Scalability: Managing and searching through large databases efficiently is difficult, especially as the size and number of documents grow.\n",
      "Latency: Retrieval processes can introduce latency, impacting the response time of the system, which is critical for applications requiring real-time interactions, like conversational agents.\n",
      "Synchronization: Keeping the retrieval database up-to-date with the latest information requires a synchronization mechanism that can handle constant updates without degrading performance.\n",
      "Limitations of Current RAG Models\n",
      "Current RAG models also have some limitations:\n",
      "Context Limitation: RAG models may struggle when the context required to generate a response exceeds the size limitations of the model’s input window.\n",
      "Retrieval Errors: The quality of the generated response is heavily dependent on the quality of the retrieval step; if irrelevant information is retrieved, the generation will suffer.\n",
      "Bias: RAG models can inadvertently propagate and even amplify biases present in the data sources they retrieve information from.\n",
      "Potential Areas for Improvement\n",
      "There are several potential areas for improvement in RAG systems:\n",
      "Better Integration: Smoother integration of the retrieval and generation components could lead to improvements in the model’s ability to handle complex queries.\n",
      "Enhanced Retrieval Algorithms: More sophisticated retrieval algorithms could provide more accurate and relevant context, improving the overall quality of the generated content.\n",
      "Adaptive Learning: Incorporating mechanisms that allow the model to learn from its retrieval successes and failures can refine the system over time.\n",
      "Data Dependency and Retrieval Sources\n",
      "The effectiveness of a RAG system is directly tied to the quality of the data in the retrieval database. Poor quality or outdated information can lead to incorrect outputs. Ensuring that the sources of information are reliable and authoritative is critical, especially for applications like healthcare and education. Additionally, handling sensitive information requires robust data privacy and security measures.\n",
      "Emerging Trends and Ongoing Research\n",
      "Several emerging trends and ongoing research efforts are focused on enhancing RAG systems:\n",
      "Cross-modal Retrieval: Expanding RAG capabilities to retrieve not only textual information but also data from other modalities like images and videos, enabling richer multi-modal responses.\n",
      "Continuous Learning: Developing RAG systems that learn from each interaction, thus improving their retrieval and generation capabilities over time without the need for retraining.\n",
      "Interactive Retrieval: Enhancing the retrieval process to be more interactive, allowing the generator to ask for more information or clarification, much like a human would in a dialogue.\n",
      "Domain Adaptation: Tailoring RAG models for specific domains, such as legal or medical, to improve the relevance and accuracy of information retrieval.\n",
      "Potential Future Enhancements\n",
      "Personalization: Integrating user profiles and historical interactions to personalize responses, making RAG models more effective in customer service and recommendation systems.\n",
      "Knowledge Grounding: Using external knowledge bases not just for retrieval but also for grounding the responses in verifiable facts, which is crucial for educational and informational applications.\n",
      "Efficient Indexing: Employing more efficient data structures and algorithms for indexing the database to speed up retrieval and reduce computational costs.\n",
      "What is a Hallucination?\n",
      "A hallucination in AI refers to when a model generates information or responses that sound plausible but are factually incorrect or unsupported by the training data.\n",
      "Understanding Hallucinations in AI\n",
      "Characteristics:\n",
      "Inaccuracy: The generated text may contain false statements or incorrect information.\n",
      "Irrelevance: The response might include details that are not relevant to the input or context.\n",
      "Invented Content: The model may create entirely fabricated details or scenarios that do not exist.\n",
      "Mitigating Hallucinations\n",
      "Improving Training Data: Ensuring that the training data is comprehensive, accurate, and representative of real-world knowledge can help reduce hallucinations.\n",
      "Fine-Tuning: Fine-tuning models on specific, high-quality datasets relevant to the task can improve accuracy and relevance.\n",
      "RAG: Combining retrieval mechanisms with generation can help ground the model's responses in actual data, reducing the likelihood of hallucinations.\n",
      "Human-in-the-Loop: Incorporating human oversight and feedback can help identify and correct hallucinations.\n",
      "Prompt Engineering\n",
      "Prompt engineering is the process of designing and refining the input prompts given to large language models (LLMs) to achieve desired outputs. It involves crafting the phrasing, structure, and content of prompts to guide the model in generating accurate, relevant, and contextually appropriate responses. Prompt engineering is essential for maximizing the effectiveness of LLMs in various applications, such as natural language understanding, text generation, and question answering.\n",
      "Key Aspects of Prompt Engineering:\n",
      "Clarity and Specificity: Ensuring that the prompt is clear and specific to minimize ambiguity and guide the AI towards the desired response.\n",
      "Context Provision: Providing sufficient context within the prompt to help the AI understand the background and nuances of the query.\n",
      "Instruction Format: Using direct and structured instructions, such as step-by-step guidance or bullet points, to improve the quality of the response.\n",
      "Iterative Refinement: Continuously refining the prompt based on the outputs received, adjusting the wording, structure, and details to enhance performance.\n",
      "Examples and Templates: Including examples or templates in the prompt to illustrate the expected format or style of the response.\n",
      "Chain of Thought (CoT)\n",
      "Chain of thought (CoT) is a technique used in prompt engineering to improve the reasoning capabilities of language models. It involves breaking down complex problems or tasks into a series of intermediate steps or logical sequences, guiding the AI through a structured process to arrive at the final answer. This approach helps the model to better understand and solve multi-step problems by explicitly modeling the reasoning process.\n",
      "Examples of Chain of Thought Prompts:\n",
      "Math Problem:\n",
      "Simple Prompt: \"What is 24 times 17?\"\n",
      "CoT Prompt: \"To calculate 24 times 17, first break it down into smaller steps. Multiply 24 by 10 to get 240. Then multiply 24 by 7 to get 168. Finally, add 240 and 168 to get the final answer.\"\n",
      "Logical Reasoning:\n",
      "Simple Prompt: \"If all roses are flowers and some flowers fade quickly, do all roses fade quickly?\"\n",
      "CoT Prompt: \"First, establish that all roses are flowers. Next, note that some flowers fade quickly. This means that while some flowers fade quickly, it does not necessarily mean all flowers do. Therefore, it is not certain that all roses fade quickly.\"\n",
      "Few-Shot Learning\n",
      "Few-shot learning is a machine learning approach where models are trained to perform tasks with only a small number of examples. In the context of large language models (LLMs), few-shot learning allows the model to generalize from a limited set of examples provided in the prompt. This capability is particularly valuable because it enables the model to adapt to new tasks or domains with minimal data, making it highly versatile and efficient.\n",
      "Key Concepts of Few-Shot Learning in LLMs:\n",
      "Minimal Training Data: Few-shot learning involves providing the model with only a few examples of the task at hand. This contrasts with traditional learning methods that require large datasets for training.\n",
      "Prompt-Based Learning: In LLMs, few-shot learning is achieved by including a few examples of the desired task within the prompt. The model uses these examples to infer the pattern and generate appropriate responses for new inputs.\n",
      "Generalization: The model leverages its pre-trained knowledge to generalize from the few examples provided, allowing it to perform well on unseen data.\n",
      "Transfer Learning: Few-shot learning often builds on the foundation of a pre-trained model through transfer learning. In transfer learning, the model is initially trained on a large, diverse dataset to acquire general knowledge. This pre-training provides a strong base, which the model can then adapt to specific tasks with minimal additional data. Few-shot learning is a specific application of transfer learning where the model adapts to new tasks using only a few examples.\n",
      "Multimodal Models\n",
      "Multimodal models are advanced machine learning models designed to process and integrate information from multiple types of data, or modalities, such as text, images, audio, and video. These models aim to understand and generate responses that consider information from different sources simultaneously, enhancing their ability to perform complex tasks that involve diverse data inputs.\n",
      "Key Concepts of Multimodal Models:\n",
      "Multiple Modalities: Multimodal models can handle and integrate various types of data, including:\n",
      "Text: Natural language processing (NLP) for understanding and generating text.\n",
      "Images: Computer vision for recognizing and interpreting visual content.\n",
      "Audio: Speech recognition and processing for understanding spoken language or sounds.\n",
      "Video: Combining both visual and auditory information from video content.\n",
      "Integration of Information: These models are designed to combine information from different modalities to create a more comprehensive understanding of the input data. This integration can lead to more accurate and contextually relevant outputs.\n",
      "Cross-Modal Learning: Multimodal models often involve learning relationships and correlations between different modalities. For example, associating textual descriptions with corresponding images or aligning spoken words with their textual transcriptions.\n",
      "Applications: Multimodal models are used in various applications, including:\n",
      "Image Captioning: Generating textual descriptions for images.\n",
      "Visual Question Answering (VQA): Answering questions based on visual content.\n",
      "Speech-to-Text and Text-to-Speech: Converting spoken language to text and vice versa.\n",
      "Multimodal Sentiment Analysis: Analyzing sentiment by combining text and audio (tone of voice).\n",
      "Examples of Multimodal Models:\n",
      "CLIP (Contrastive Language-Image Pre-training): Developed by OpenAI, CLIP is trained to understand images and their associated textual descriptions. It can perform tasks like image classification and zero-shot image recognition by leveraging both visual and textual information.\n",
      "DALL-E: Another model from OpenAI, DALL-E generates images from textual descriptions. It combines NLP and computer vision to create novel images based on the input text.\n",
      "VQA Models: These models are designed to answer questions about images. They integrate visual information from the image with textual information from the question to generate accurate answers.\n",
      "Speech-Text Models: Models like Google's WaveNet or OpenAI's Jukebox integrate audio and text data to generate realistic speech or music from textual inputs.\n",
      "Evaluation\n",
      "Evaluation in LLMs measures model performance using metrics such as accuracy, relevance, and coherence, assessing how well the model fulfills its intended purpose and meets user needs. LLM-based applications require systematic testing and evaluation due to their complexity.\n",
      "How to Evaluate Large Language Models (LLMs)\n",
      "Large language models (LLMs) use deep learning techniques to analyze and generate natural language. These models have become increasingly popular due to their ability to perform a wide range of language-related tasks such as language translation, text summarization, and question-answering. However, evaluating the performance of LLMs requires a careful analysis of various factors:\n",
      "Quality and Quantity of Training Data: The most crucial element in evaluating LLMs is the quality and quantity of the training data used. The training data should be diverse and representative of the target language and domain to ensure that the LLM can learn and generalize language patterns effectively. Moreover, the training data should be annotated with relevant labels or tags to enable supervised learning, which is the most commonly used approach in LLMs.\n",
      "Model Size: Generally, larger models have better performance, but they also require more computational resources to train and run. Researchers often need to balance model size and performance, depending on the specific task and available resources. It is also worth noting that larger models tend to be more prone to overfitting, which can lead to poor generalization performance on new data.\n",
      "Speed of Inference: Speed of inference is an important factor, especially when deploying LLMs in real-world applications. Faster inference times are desirable as they enable the LLM to process large amounts of data efficiently. Techniques such as pruning, quantization, and distillation have been proposed to reduce the size and improve the speed of LLMs.\n",
      "To evaluate the performance of large language models (LLMs), researchers often use benchmarks—standardized datasets and evaluation metrics for specific language-related tasks. Benchmarks enable fair comparisons between different models and methods, helping to identify the strengths and weaknesses of LLMs. Common benchmarks include:\n",
      "GLUE (General Language Understanding Evaluation): A benchmark designed to evaluate and analyze the performance of models across a diverse set of natural language understanding tasks.\n",
      "SuperGLUE: An advanced version of GLUE, designed to be more challenging and to push the boundaries of what LLMs can achieve in natural language understanding.\n",
      "CoQA (Conversational Question Answering): A benchmark for evaluating the ability of LLMs to understand and generate responses in a conversational context.\n",
      "By using these benchmarks, researchers can systematically assess the performance of LLMs, ensuring that comparisons are consistent and meaningful. This process helps in identifying areas where models excel and where they need improvement, guiding future development and optimization efforts.\n",
      "Monitoring\n",
      "Monitoring involves tracking an LLM’s performance in real-time use to ensure accuracy, reliability, and ethical standards are maintained, often incorporating feedback to improve model outputs over time. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chunk_by_paragraphs(text, max_chars=1000):\n",
    "    \"\"\"\n",
    "    Split text into chunks based on paragraphs\n",
    "    \"\"\"\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        if len(current_chunk) + len(para) <= max_chars:\n",
    "            current_chunk += para + \"\\n\\n\"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = para + \"\\n\\n\"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Try paragraph-based chunking\n",
    "para_chunks = chunk_by_paragraphs(text)\n",
    "print(f\"Number of paragraph-based chunks: {len(para_chunks)}\")\n",
    "print(\"\\nFirst two chunks:\")\n",
    "print(\"Chunk 1:\", para_chunks[0], \"\\n\")\n",
    "print(\"Chunk 2:\", para_chunks[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task 2\n",
    "Your turn! Experiment with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small chunks (200 chars, no overlap):\n",
      "Number of chunks: 251\n",
      "First chunk: Topics\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. \n",
      "\n",
      "Large chunks (1000 chars, 100 char overlap):\n",
      "Number of chunks: 46\n",
      "First chunk: Topics\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. These deep learning algorithms are trained on massive datasets of text, enabling them to predict and generate language based on given prompts. By learning patterns, structures, and relationships in text, LLMs can produce human-like responses.\n",
      "LLMs are a subset of a broader technology known as language models, which all share the ability to process and generate text that resembles natural language, performing tasks related to natural language processing (NLP). However, LLMs stand out due to their significant size, characterized by two main factors:\n",
      "Large Training Datasets: LLMs are trained using vast amounts of data, allowing them to learn a wide range of language patterns and nuances.\n",
      "Huge Number of Learnable Parameters: LLMs have a massive number of learnable parameters. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try these experiments:\n",
    "# 1. Change chunk sizes (try 200, 1000 characters)\n",
    "# 2. Modify overlap (try 0, 100 characters)\n",
    "# 3. Compare the results\n",
    "\n",
    "# Example with different parameters:\n",
    "small_chunks = chunk_by_characters(text, chunk_size=200, overlap=0)\n",
    "large_chunks = chunk_by_characters(text, chunk_size=1000, overlap=100)\n",
    "\n",
    "print(\"Small chunks (200 chars, no overlap):\")\n",
    "print(f\"Number of chunks: {len(small_chunks)}\")\n",
    "print(\"First chunk:\", small_chunks[0], \"\\n\")\n",
    "\n",
    "print(\"Large chunks (1000 chars, 100 char overlap):\")\n",
    "print(f\"Number of chunks: {len(large_chunks)}\")\n",
    "print(\"First chunk:\", large_chunks[0], \"\\n\")\n",
    "\n",
    "# Discussion points:\n",
    "# - How does chunk size affect the coherence of the text?\n",
    "# - What happens to the meaning when chunks are too small?\n",
    "# - How does overlap help maintain context between chunks?\n",
    "# - Which method works better for this specific text? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Now that we have learned about Embeddings and Chunking, let's run a Pratical RAG example combining the concepts we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the benefits of RAG?\n",
      "Relevant chunk: Applications of RAG\n",
      "RAG has numerous applications across various domains, significantly enhancing the quality and relevance of the outputs generated by language models:\n",
      "Enhancing Chatbots and Conversa...\n",
      "\n",
      "Q: How do embeddings work?\n",
      "Relevant chunk: Topics\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large Language Models (LLMs) are a type of artificial intelligence designed to understand and generate human language. These deep learning algorithms are ...\n"
     ]
    }
   ],
   "source": [
    "# Simple RAG implementation combining embeddings and chunks\n",
    "def simple_rag(query, chunks, model):\n",
    "    # 1. Embed query and chunks\n",
    "    query_emb = model.encode(query)\n",
    "    chunk_embs = model.encode(chunks)\n",
    "    \n",
    "    # 2. Find most relevant chunk\n",
    "    similarities = [cosine_similarity(query_emb, chunk_emb) for chunk_emb in chunk_embs]\n",
    "    best_chunk = chunks[np.argmax(similarities)]\n",
    "    \n",
    "    return best_chunk\n",
    "\n",
    "questions = [\n",
    "    \"What are the benefits of RAG?\",\n",
    "    \"How do embeddings work?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    relevant_chunk = simple_rag(q, para_chunks, model)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(f\"Relevant chunk: {relevant_chunk[:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
